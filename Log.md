# 100 Days Of ML - LOG

## Day 0 : August 30, 2020
 
**Today's Progress** : I have setup all the things I needed to complete this challenge (Hopefully).

**Thoughts** : Today was hectic. One thing led to another and it took me several hours. Hope this will be exciting, will help me in learning Machine Learning in a more effective way.

## Day 1 : August 31, 2020

**Today's Progress** : I started learning the basics of ML about surpervised learning and unsupervised learning, linear regression, clustering, etc.

**Thoughts** : It was really fun. Octave is a good platform to learn ML as a beginner. I put in extra efforts to google whatever I didn't understand by pausing the video at the moment itself and not keeping it for later.

## Day 2 : September 01, 2020

**Today's Progress** :  
1. Applications of square errored function, cost function, contour plots, computation of gradient descent.
1. Predicted multiple linear regression hypotheses simultaneously using matrices in Octave.
     
**Thoughts** : The entire process of analysing both gradient descent and linear regression individually and then implementing the batch gradient descent algorithm to the linear regression model was really fascinating and fun. Things seem to be really obvious once you understand them truly.

**Link of Work:**  [Day2](https://github.com/kritanjalijain/Blog--100_Days_0f_ML/tree/master/Day2)

## Day 3 : September 02, 2020

**Today's Progress** :  
1. Completed onramp MATALB course about the basics of MATLAB (matrix manipulations, plotting of functions and data, implementation of algorithms), importing and visualizing data and implemented it in projects.
1. The projects made were-
   1. Electricity usage and prices- Project to plot electricity usage and prices for various economic sectors.
   1. Audio frequency- Project to plot a signal that contains beat phenomenon and then analyze the signal's frequency content.
   1. Stellar motion-  Project to find and determine how fast the star is moving away from earth by using the wavelength characteristic spectrum of star.
   
**Thoughts** : Getting to use MATLAB a multi-paradigm numerical computing environment and proprietary programming language was fun. Using MATLAB to predict stuff in real life examples was really fascinating.

**Link of Work:**  [Day3_Projects](https://github.com/kritanjalijain/Blog--100_Days_0f_ML/tree/master/Day3_Projects)

## Day 4 : September 03, 2020

**Today's Progress** :  
1. Implemented multivariant linear regression and predicted form of hypothesis when it has multiple features.
   1. Learnt how to fit the parameters of that hypothesis. In particular, about how to use gradient descent for linear regression with multiple features.
   1. Applications of feature scaling and mean normalization to gradient descent, debugging gradient descent, automatic convergence test and choosing a suitably small learning rate.
   1. Implementation of normal equation vs gradient descent.
1. Predicted cost function using polynomial regression.
1. Apart from octave and MATLAB, I scratched the surface of ML using python libraries like Pandas, Numpy and OpenCV.
     
**Thoughts** : Today was a bit overwhelhming but exciting. I'm really eager to dive deeper into machine learning.

## Day 5 : September 04, 2020

**Today's Progress** :  
1. Project- Predict the profits of a restaurant using linear regression from batch gradient descent algorithm and plot it's contour plot and surface plot.
   
**Thoughts** : The entire process of analysing both gradient descent and linear regression individually and then implementing the batch gradient descent algorithm to the linear regression model was really fascinating and fun. Things seem to be really obvious once you understand them truly.

**Link of Work:**  [Day5_Projects](https://github.com/kritanjalijain/Blog--100_Days_0f_ML/tree/master/Day5_Projects)

## Day 6 : September 05, 2020

**Today's Progress** :  
1. Project- Predict and plot the prices of houses using multivariant linear regression, from both normal equation and gradient descent algorithm.
1. Explored Numpy.
   
**Thoughts** : Visualizing data really helps understand the model better.

**Link of Work:**  [Day6_Projects](https://github.com/kritanjalijain/)

## Day 7 : September 07, 2020

**Today's Progress** :  
 Classification problems - 
   * Hypothesis representation, visualisation of *logistic regression*; decision boundary.
   
**Thoughts** : Finally got to know applications of the logistic function or the sigmoid function which I studied in 11th grade. I can finally understand the real life applications of matrices, algebra and calculus studied previously. Well, this is fun :)

## Day 8 : September 08, 2020

**Today's Progress** :  
 Classification problems -
   * Derivation of cost function for logisitic regression
   * Gradient descent for minimizing the cost function J of theta for logistic regression.
  
 Basics of sophisticated optimization algorithms like-
  * Conjugate gradient 
  * BFGS 
  * L-BFGS 

**Thoughts** : Finally got to know applications of the logistic function or the sigmoid function which I studied in 11th grade. I can finally understand the real life applications of matrices, algebra and calculus studied previously. Well, this is fun :)

## Day 9 : September 09, 2020

**Today's Progress** :  
 Multi-Classification problems -
   * One vs All
   * Derivation of cost function for logisitic regression
   * Gradient descent for minimizing the cost function J of theta for logistic regression.

**Thoughts** : 

## Day 10 : September 10, 2020

**Today's Progress** :  
   * Regularization to help ameliorate models from overfitting the training data.(Since machine learning models need to generalize well to new examples that the model has not seen in practice.)
   
**Thoughts** : Choosing a model with an appropriate algorithm is essential and an algorithm fiiting the data too perfectly (over-fitting) is not appropriate at times since it has high variance just like underfitting has high bias. 

## Day 11 : September 11, 2020

**Today's Progress** :  
   * Ridge and lasso regularization
   
**Thoughts** :  

**Link of Work** : [Day11_Projects](https://github.com/kritanjalijain/100_Days_0f_ML/tree/master/Day11_Projects)

## Day 12 : September 12, 2020

**Today's Progress** :  
   * Regularization to help ameliorate models from overfitting the training data.(Since machine learning models need to generalize well to new examples that the model has not seen in practice.)
   
**Thoughts** : 

**Link of Work** : [Day12_Projects](https://github.com/kritanjalijain/100_Days_0f_ML/tree/master/Day12_Projects)

## Day 13 : September 13, 2020

**Today's Progress** :  
   * Neural Networks
   
**Thoughts** : One of the reasons they excite me is that maybe they give us this window into what we might do if we're also thinking of what algorithms might someday be able to learn in a manner similar to humankind. 

## Day 14 : September 14, 2020

**Today's Progress** :  
   * Neural Networks
   
**Thoughts** :

## Day 15 : September 15, 2020

**Today's Progress** :  
   * Neural Networks
   
**Thoughts** :
