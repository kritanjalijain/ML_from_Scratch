# 100 Days Of ML - LOG

## Day 0 : August 30, 2020
 
**Today's Progress** : I have setup all the things I needed to complete this challenge (Hopefully).

**Thoughts** : Today was hectic. One thing led to another and it took me several hours. Hope this will be exciting, will help me in learning Machine Learning in a more effective way.

## Day 1 : August 31, 2020

**Today's Progress** : I started Andrew Ng's course about learning the basics of ML and completed 1/3rd of Week 1.

**Thoughts** : It was really fun. Octave is a good platform to learn ML as a beginner. Today I learnt about surpervised learning and unsupervised learning, linear regression, clustering, etc.
I put in extra efforts to google whatever I didn't understand by pausing the video at the moment itself and not keeping it for later.

## Day 2 : September 01, 2020

**Today's Progress** :  
1. Applications of square errored function, cost function, contour plots, computation of gradient descent.
1. Predicted multiple linear regression hypotheses simultaneously using matrices in Octave.
   1. Item 3a
   1. Item 3b
   
**Thoughts** : The entire process of analysing both gradient descent and linear regression individually and then implementing the batch gradient descent algorithm to the linear regression model was really fascinating and fun. Things seem to be really obvious once you understand them truly.

**Link of Work:**  [Commit](https://github.com/LordSomen/100DaysOfML/commit/5cf906d86324c52dbd90896a57ee951befdcf0e3)

## Day 4 : September 02, 2020

**Today's Progress** :  
1. Completed onramp MATALB course about the basics of MATLAB and implemented it in three projects.
1. Predicted Stellar motion in MATLAB.
   1. Item 3a
   1. Item 3b
   
**Thoughts** : The entire process of analysing both gradient descent and linear regression individually and then implementing the batch gradient descent algorithm to the linear regression model was really fascinating and fun. Things seem to be really obvious once you understand them truly.

**Link of Work:**  [Commit](https://github.com/LordSomen/100DaysOfML/commit/5cf906d86324c52dbd90896a57ee951befdcf0e3)

## Day 5 : September 03, 2020

**Today's Progress** :  
1. Implemented multivariant linear regression and predicted form of hypothesis when it has multiple features.
1. Learnt how to fit the parameters of that hypothesis. In particular, about how to use gradient descent for linear regression with multiple features.
1. Applications of feature scaling and mean normalization to gradient descent, debugging gradient descent, automatic convergence test and choosing a suitably small learning rate.
1. Predicted cost function using polynomial regression.
1. Apart from octave and MATLAB, I explored ML using python libraries like Pandas, Numpy and OpenCV.
     
**Thoughts** : The entire process of analysing both gradient descent and linear regression individually and then implementing the batch gradient descent algorithm to the linear regression model was really fascinating and fun. Things seem to be really obvious once you understand them truly.

**Link of Work:**  [Commit](https://github.com/LordSomen/100DaysOfML/commit/5cf906d86324c52dbd90896a57ee951befdcf0e3)

